// Code generated - EDITING IS FUTILE. DO NOT EDIT.
//
// Generated by pipeline:
//     terraform
// Using jennies:
//     TerraformDataSourceJenny
//     ComposableLatestMajorsOrXJenny
//
// Run 'go generate ./' from repository root to regenerate.

package provider

import (
	"context"
	"encoding/json"

	"github.com/hashicorp/terraform-plugin-framework/attr"
	"github.com/hashicorp/terraform-plugin-framework/datasource"
	"github.com/hashicorp/terraform-plugin-framework/datasource/schema"
	"github.com/hashicorp/terraform-plugin-framework/diag"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"
)

// Ensure that the imports are used to avoid compiler errors.
var _ attr.Value
var _ diag.Diagnostic

// Ensure provider defined types fully satisfy framework interfaces.
var (
	_ datasource.DataSource              = &QueryPrometheusDataSource{}
	_ datasource.DataSourceWithConfigure = &QueryPrometheusDataSource{}
)

func NewQueryPrometheusDataSource() datasource.DataSource {
	return &QueryPrometheusDataSource{}
}

// QueryPrometheusDataSource defines the data source implementation.
type QueryPrometheusDataSource struct{}

type QueryPrometheusDataSourceModel struct {
	RenderedJSON   types.String  `tfsdk:"rendered_json"`
	Expr           types.String  `tfsdk:"expr"`
	Instant        types.Bool    `tfsdk:"instant"`
	Range          types.Bool    `tfsdk:"range"`
	Exemplar       types.Bool    `tfsdk:"exemplar"`
	EditorMode     types.String  `tfsdk:"editor_mode"`
	Format         types.String  `tfsdk:"format"`
	LegendFormat   types.String  `tfsdk:"legend_format"`
	IntervalFactor types.Float64 `tfsdk:"interval_factor"`
	RefId          types.String  `tfsdk:"ref_id"`
	Hide           types.Bool    `tfsdk:"hide"`
	QueryType      types.String  `tfsdk:"query_type"`
}

func (m QueryPrometheusDataSourceModel) MarshalJSON() ([]byte, error) {
	type jsonQueryPrometheusDataSourceModel struct {
		Expr           string   `json:"expr"`
		Instant        *bool    `json:"instant,omitempty"`
		Range          *bool    `json:"range,omitempty"`
		Exemplar       *bool    `json:"exemplar,omitempty"`
		EditorMode     *string  `json:"editorMode,omitempty"`
		Format         *string  `json:"format,omitempty"`
		LegendFormat   *string  `json:"legendFormat,omitempty"`
		IntervalFactor *float64 `json:"intervalFactor,omitempty"`
		RefId          string   `json:"refId"`
		Hide           *bool    `json:"hide,omitempty"`
		QueryType      *string  `json:"queryType,omitempty"`
	}

	m = m.ApplyDefaults()
	attr_expr := m.Expr.ValueString()
	attr_instant := m.Instant.ValueBoolPointer()
	attr_range := m.Range.ValueBoolPointer()
	attr_exemplar := m.Exemplar.ValueBoolPointer()
	attr_editormode := m.EditorMode.ValueStringPointer()
	attr_format := m.Format.ValueStringPointer()
	attr_legendformat := m.LegendFormat.ValueStringPointer()
	attr_intervalfactor := m.IntervalFactor.ValueFloat64Pointer()
	attr_refid := m.RefId.ValueString()
	attr_hide := m.Hide.ValueBoolPointer()
	attr_querytype := m.QueryType.ValueStringPointer()

	model := &jsonQueryPrometheusDataSourceModel{
		Expr:           attr_expr,
		Instant:        attr_instant,
		Range:          attr_range,
		Exemplar:       attr_exemplar,
		EditorMode:     attr_editormode,
		Format:         attr_format,
		LegendFormat:   attr_legendformat,
		IntervalFactor: attr_intervalfactor,
		RefId:          attr_refid,
		Hide:           attr_hide,
		QueryType:      attr_querytype,
	}
	return json.Marshal(model)
}

func (m QueryPrometheusDataSourceModel) ApplyDefaults() QueryPrometheusDataSourceModel {

	return m
}

func (d *QueryPrometheusDataSource) Metadata(ctx context.Context, req datasource.MetadataRequest, resp *datasource.MetadataResponse) {
	resp.TypeName = req.ProviderTypeName + "_query_prometheus"
}

func (d *QueryPrometheusDataSource) Schema(ctx context.Context, req datasource.SchemaRequest, resp *datasource.SchemaResponse) {
	resp.Schema = schema.Schema{
		// This description is used by the documentation generator and the language server.
		MarkdownDescription: "",
		Attributes: map[string]schema.Attribute{
			"expr": schema.StringAttribute{
				MarkdownDescription: `The actual expression/query that will be evaluated by Prometheus`,
				Computed:            false,
				Optional:            false,
				Required:            true,
			},
			"instant": schema.BoolAttribute{
				MarkdownDescription: `Returns only the latest value that Prometheus has scraped for the requested time series`,
				Computed:            false,
				Optional:            true,
				Required:            false,
			},
			"range": schema.BoolAttribute{
				MarkdownDescription: `Returns a Range vector, comprised of a set of time series containing a range of data points over time for each time series`,
				Computed:            false,
				Optional:            true,
				Required:            false,
			},
			"exemplar": schema.BoolAttribute{
				MarkdownDescription: `Execute an additional query to identify interesting raw samples relevant for the given expr`,
				Computed:            false,
				Optional:            true,
				Required:            false,
			},
			"editor_mode": schema.StringAttribute{
				MarkdownDescription: `Specifies which editor is being used to prepare the query. It can be "code" or "builder"`,
				Computed:            false,
				Optional:            true,
				Required:            false,
			},
			"format": schema.StringAttribute{
				MarkdownDescription: `Query format to determine how to display data points in panel. It can be "time_series", "table", "heatmap"`,
				Computed:            false,
				Optional:            true,
				Required:            false,
			},
			"legend_format": schema.StringAttribute{
				MarkdownDescription: `Series name override or template. Ex. ` + "{{`{{hostname}}`}}" + ` will be replaced with label value for hostname`,
				Computed:            false,
				Optional:            true,
				Required:            false,
			},
			"interval_factor": schema.Float64Attribute{
				MarkdownDescription: `@deprecated Used to specify how many times to divide max data points by. We use max data points under query options
See https://github.com/grafana/grafana/issues/48081`,
				Computed: false,
				Optional: true,
				Required: false,
				DeprecationMessage: `Used to specify how many times to divide max data points by. We use max data points under query options
See https://github.com/grafana/grafana/issues/48081`,
			},
			"ref_id": schema.StringAttribute{
				MarkdownDescription: `A unique identifier for the query within the list of targets.
In server side expressions, the refId is used as a variable name to identify results.
By default, the UI will assign A->Z; however setting meaningful names may be useful.`,
				Computed: false,
				Optional: false,
				Required: true,
			},
			"hide": schema.BoolAttribute{
				MarkdownDescription: `true if query is disabled (ie should not be returned to the dashboard)
Note this does not always imply that the query should not be executed since
the results from a hidden query may be used as the input to other queries (SSE etc)`,
				Computed: false,
				Optional: true,
				Required: false,
			},
			"query_type": schema.StringAttribute{
				MarkdownDescription: `Specify the query flavor
TODO make this required and give it a default`,
				Computed: false,
				Optional: true,
				Required: false,
			},

			"rendered_json": schema.StringAttribute{
				Computed:            true,
				MarkdownDescription: "This datasource rendered as JSON",
			},
		},
	}
}

func (d *QueryPrometheusDataSource) Configure(ctx context.Context, req datasource.ConfigureRequest, resp *datasource.ConfigureResponse) {
}

func (d *QueryPrometheusDataSource) Read(ctx context.Context, req datasource.ReadRequest, resp *datasource.ReadResponse) {
	var data QueryPrometheusDataSourceModel

	// Read Terraform configuration data into the model
	resp.Diagnostics.Append(req.Config.Get(ctx, &data)...)

	if resp.Diagnostics.HasError() {
		return
	}

	JSONConfig, err := json.Marshal(data)
	if err != nil {
		resp.Diagnostics.AddError("JSON marshalling error", err.Error())
		return
	}

	// Not sure about that
	data.RenderedJSON = types.StringValue(string(JSONConfig))

	// Write logs using the tflog package
	// Documentation: https://terraform.io/plugin/log
	tflog.Trace(ctx, "read a data source")

	// Save data into Terraform state
	resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)
}
